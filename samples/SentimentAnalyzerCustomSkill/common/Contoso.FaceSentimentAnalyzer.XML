<?xml version="1.0"?>
<doc>
    <assembly>
        <name>Contoso.FaceSentimentAnalyzer</name>
    </assembly>
    <members>
        <member name="T:Contoso.FaceSentimentAnalyzer.SentimentType">
            <summary>
            Defines the set of possible emotion label scored by this skill
            </summary>
        </member>
        <member name="T:Contoso.FaceSentimentAnalyzer.FaceSentimentAnalyzerBinding">
            <summary>
            FaceSentimentAnalyzerBinding class.
            It holds the input and output passed and retrieved from a FaceSentimentAnalyzerSkill instance.
            </summary>
        </member>
        <member name="M:Contoso.FaceSentimentAnalyzer.FaceSentimentAnalyzerBinding.#ctor(Microsoft.AI.Skills.SkillInterface.ISkillDescriptor,Microsoft.AI.Skills.SkillInterface.ISkillExecutionDevice,Windows.AI.MachineLearning.LearningModelSession)">
            <summary>
            FaceSentimentAnalyzerBinding constructor
            </summary>
        </member>
        <member name="M:Contoso.FaceSentimentAnalyzer.FaceSentimentAnalyzerBinding.SetInputImageAsync(Windows.Media.VideoFrame)">
            <summary>
            Sets the input image to be processed by the skill
            </summary>
            <param name="frame"></param>
            <returns></returns>
        </member>
        <member name="P:Contoso.FaceSentimentAnalyzer.FaceSentimentAnalyzerBinding.IsFaceFound">
            <summary>
            Returns whether or not a face is found given the bound outputs
            </summary>
        </member>
        <member name="P:Contoso.FaceSentimentAnalyzer.FaceSentimentAnalyzerBinding.PredominantSentiments">
            <summary>
            Returns the sentiments with the highest score for each face detected
            </summary>
            <returns></returns>
        </member>
        <member name="P:Contoso.FaceSentimentAnalyzer.FaceSentimentAnalyzerBinding.FaceBoundingBoxes">
            <summary>
            Returns the bounding boxes around each detected face
            </summary>
            <returns></returns>
        </member>
        <member name="T:Contoso.FaceSentimentAnalyzer.FaceSentimentAnalyzerConst">
            <summary>
            Set of contant values used throughout the skill
            </summary>
        </member>
        <member name="T:Contoso.FaceSentimentAnalyzer.FaceSentimentAnalyzerDescriptor">
            <summary>
            FaceSentimentAnalyzerDescriptor class.
            Exposes information about the skill and its input/output variable requirements.
            Also acts as a factory for FaceSentimentAnalyzerSkill
            </summary>
        </member>
        <member name="M:Contoso.FaceSentimentAnalyzer.FaceSentimentAnalyzerDescriptor.#ctor">
            <summary>
            FaceSentimentAnalyzerDescriptor constructor
            </summary>
        </member>
        <member name="M:Contoso.FaceSentimentAnalyzer.FaceSentimentAnalyzerDescriptor.GetSupportedExecutionDevicesAsync">
            <summary>
            Retrieves a list of supported ISkillExecutionDevice to run the skill logic on.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Contoso.FaceSentimentAnalyzer.FaceSentimentAnalyzerDescriptor.CreateSkillAsync">
            <summary>
            Factory method for instantiating and initializing the skill.
            Let the skill decide of the optimal or default ISkillExecutionDevice available to use.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Contoso.FaceSentimentAnalyzer.FaceSentimentAnalyzerDescriptor.CreateSkillAsync(Microsoft.AI.Skills.SkillInterface.ISkillExecutionDevice)">
            <summary>
            Factory method for instantiating and initializing the skill.
            </summary>
            <param name="executionDevice"></param>
            <returns></returns>
        </member>
        <member name="P:Contoso.FaceSentimentAnalyzer.FaceSentimentAnalyzerDescriptor.Information">
            <summary>
            Returns the information concerning this skill such as Name, Description, etc.
            </summary>
        </member>
        <member name="P:Contoso.FaceSentimentAnalyzer.FaceSentimentAnalyzerDescriptor.InputFeatureDescriptors">
            <summary>
            Returns a list of descriptors that correlate with each input SkillFeature.
            </summary>
        </member>
        <member name="P:Contoso.FaceSentimentAnalyzer.FaceSentimentAnalyzerDescriptor.Metadata">
            <summary>
            Returns a set of metadata that may control the skill execution differently than by feeding an input 
            i.e. internal state, sub-process execution frequency, etc.
            </summary>
        </member>
        <member name="P:Contoso.FaceSentimentAnalyzer.FaceSentimentAnalyzerDescriptor.OutputFeatureDescriptors">
            <summary>
            Returns a list of descriptors that correlate with each output SkillFeature.
            </summary>
        </member>
        <member name="T:Contoso.FaceSentimentAnalyzer.FaceSentimentAnalyzerSkill">
            <summary>
            FaceSentimentAnalyzerSkill class.
            Contains the main execution logic of the skill, findind a face in an image then running an ML model to infer its sentiment
            Also acts as a factory for FaceSentimentAnalyzerBinding
            to obtain the ONNX model used in this skill, refer to https://github.com/onnx/models/tree/master/emotion_ferplus
            </summary>
        </member>
        <member name="M:Contoso.FaceSentimentAnalyzer.FaceSentimentAnalyzerSkill.CreateAsync(Microsoft.AI.Skills.SkillInterface.ISkillDescriptor,Microsoft.AI.Skills.SkillInterface.ISkillExecutionDevice)">
            <summary>
            Creates and initializes a FaceSentimentAnalyzerSkill instance
            </summary>
            <param name="descriptor"></param>
            <param name="device"></param>
            <returns></returns>
        </member>
        <member name="M:Contoso.FaceSentimentAnalyzer.FaceSentimentAnalyzerSkill.#ctor(Microsoft.AI.Skills.SkillInterface.ISkillDescriptor,Microsoft.AI.Skills.SkillInterface.ISkillExecutionDevice)">
            <summary>
            FaceSentimentAnalyzerSkill constructor
            </summary>
            <param name="description"></param>
            <param name="device"></param>
        </member>
        <member name="M:Contoso.FaceSentimentAnalyzer.FaceSentimentAnalyzerSkill.CreateSkillBindingAsync">
            <summary>
            Factory method for instantiating FaceSentimentAnalyzerBinding
            </summary>
            <returns></returns>
        </member>
        <member name="M:Contoso.FaceSentimentAnalyzer.FaceSentimentAnalyzerSkill.EvaluateAsync(Microsoft.AI.Skills.SkillInterface.ISkillBinding)">
            <summary>
            Runs the skill against a binding object, executing the skill logic on the associated input features and populating the output ones
            This skill proceeds in 2 steps: 
            1) Run FaceDetector against the image and populate the face bound feature in the binding object
            2) If a face was detected, proceeds with sentiment analysis of that portion fo the image using Windows ML then updating the score 
            of each possible sentiment returned as result
            </summary>
            <param name="binding"></param>
            <returns></returns>
        </member>
        <member name="P:Contoso.FaceSentimentAnalyzer.FaceSentimentAnalyzerSkill.SkillDescriptor">
            <summary>
            Returns the descriptor of this skill
            </summary>
        </member>
        <member name="P:Contoso.FaceSentimentAnalyzer.FaceSentimentAnalyzerSkill.Device">
            <summary>
            Return the execution device with which this skill was initialized
            </summary>
        </member>
        <member name="M:Contoso.FaceSentimentAnalyzer.FaceSentimentAnalyzerSkill.AppendSoftMaxedInputs(System.Collections.Generic.IReadOnlyList{System.Single},System.Collections.Generic.List{System.Single}@)">
            <summary>
            Calculates SoftMax normalization over a set of data and append them to the output
            </summary>
            <param name="inputs"></param>
            <param name="outputs"></param>
            <returns></returns>
        </member>
        <member name="M:Contoso.FaceSentimentAnalyzer.FaceSentimentAnalyzerSkill.GetWinMLDevice(Microsoft.AI.Skills.SkillInterface.ISkillExecutionDevice)">
            <summary>
            If possible, retrieves a WinML LearningModelDevice that corresponds to an ISkillExecutionDevice
            </summary>
            <param name="executionDevice"></param>
            <returns></returns>
        </member>
    </members>
</doc>
