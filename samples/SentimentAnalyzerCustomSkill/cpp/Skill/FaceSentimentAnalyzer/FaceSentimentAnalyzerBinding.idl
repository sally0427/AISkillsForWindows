// Copyright (c) Microsoft Corporation. All rights reserved.

import "Common.idl";

namespace Contoso.FaceSentimentAnalyzer
{
    /// <summary>
    /// Defines the set of possible emotion label scored by this skill
    /// </summary>
    [contract(Contoso.FaceSentimentAnalyzer.FaceSentimentAnalyzerSkillAPI, 1)]
    enum SentimentType
    {
        neutral = 0,
        happiness,
        surprise,
        sadness,
        anger,
        disgust,
        fear,
        contempt
    };

    /// <summary>
    /// FaceSentimentAnalyzerBinding class
    /// It holds the input and output passed and retrieved from a FaceSentimentAnalyzerSkill instance.
    /// </summary>
    [contract(Contoso.FaceSentimentAnalyzer.FaceSentimentAnalyzerSkillAPI, 1)]
    [interface_name("Contoso.FaceSentimentAnalyzer.FaceSentimentAnalyzerBinding", AE19D8FF-4E16-4FBD-8228-147A567D681D)]
    runtimeclass FaceSentimentAnalyzerBinding : Microsoft.AI.Skills.SkillInterface.ISkillBinding
    {
        /// <summary>
        /// Set the input image to be processed by the skill
        /// </summary>
        /// <param name="frame"></param>
        /// <returns></returns>
        Windows.Foundation.IAsyncAction SetInputImageAsync(Windows.Media.VideoFrame frame);

        /// <summary>
        /// Returns whether or not a face is found given the bound outputs
        /// </summary>
        Boolean IsFaceFound{ get; };

        /// <summary>
        /// Return the sentiment with the highest score for each face detected
        /// </summary>
        /// <returns></returns>
        IVectorView<SentimentType> PredominantSentiments{ get; };

        /// <summary>
        /// Return the face rectangle
        /// </summary>
        /// <returns></returns>
        IVectorView<float> FaceBoundingBoxes{ get; };
    }
}
